\documentclass[12pt]{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{setspace,endnotes,amsmath,amsfonts,amssymb,url,graphicx,booktabs,longtable,qtree}
\usepackage[colorlinks=TRUE, citecolor=black, urlcolor=blue]{hyperref}
\usepackage[round]{natbib}
\bibpunct{(}{)}{;}{a}{}{,}
\usepackage{caption}

\setlength{\LTcapwidth}{5in}
\def\p3s{\phantom{xxx}}
\parskip=0pt
\parindent=30pt
\begin{document}

\vspace{50mm}
\date{\today}
\title{An Empirical Evaluation of Explanations for State Repression\thanks{Draft Version, Do Not Circulate}}
\bigskip
\author{Daniel W. Hill, Jr.\thanks{Assistant Professor, Department of International Affairs,
University of Georgia. email: dwhill@uga.edu.} and Zachary M. Jones\thanks{Graduate student, Pennsylvania State University. email: zmj@zmjones.com.}}

\maketitle \thispagestyle{empty}

\clearpage
\onehalfspace

\begin{abstract}
The empirical literature that examines cross-national patterns of state repression seeks to discover a set of political, economic, and social conditions that are consistently associated with government violations of human rights. Null hypothesis significance testing is the most common way of examining the relationship  between repression and concepts of interest, but we argue that it is inadequate for this goal, and has produced potentially misleading results. To remedy this deficiency in the literature we use cross-validation and random forests to determine the {\em predictive} power of measures of concepts the literature identifies as important causes of repression. We find that few of these measures are able to substantially improve the predictive power of statistical models of repression. Further, the most studied concept in the literature, democratic political institutions, predicts certain kinds of repression much more accurately than others. We argue that this is due to conceptual overlap between democracy and certain kinds of state repression. Finally, we argue that the impressive performance of certain features of domestic legal systems, as well as some economic and demographic factors, justifies a stronger focus on these concepts in future studies of repression.
\end{abstract}

\clearpage

\section{Introduction}

The past 20-30 years has witnessed the birth and tremendous growth of an empirical, quantitative literature that examines cross-national patterns of state repression \citep[See, e.g.,][]{Stohletal1986, Park1987, McCormickMitchell1988, Henderson1991, Henderson1993, PoeTate1994, Davenport1995, Fein1995, Davenport1999, CingranelliRichards1999isq, Keith1999, Poeetal1999, Apodaca2001, RichardsGellenySacko2001,  Hathaway2002, Keith2002PRQ, DavenportArmstrong2004, BDMetal2005, HafnerBurton2005jpr, HafnerBurtonTsutsui2005, Davenport2007AR, Davenport2007, KeithTatePoe2009, CingranelliFilippov2010}. The general purpose of this literature is to discover a set of political, economic, and social conditions that are consistently associated with government violations of the most basic human rights.\footnote{``The most basic human rights'' means freedom from political imprisonment, torture, kidnapping, and extrajudicial execution, generally referred to as personal, or physical, integrity rights \citep[See, e.g.][]{PoeTate1994, CingranelliRichards1999isq}.} In other words, this literature aims to answer why some governments violate basic human rights more than others. This is an enormously important question that relates directly to one of the fundamental problems of politics, which is how an entity given the exclusive authority to enforce rules through physical coercion (the state) can be prevented from abusing that authority \citep[See, e.g.,][]{Moore2010}. 

Though the basic research question explored by this literature is of tremendous intrinsic importance, the standards currently used to assess claims about the causes of state repression are inadequate. Specifically, scholars nearly always employ null hypothesis tests of statistical significance to determine if a particular covariate is a meaningful determinant of state repression. Under this approach, covariates whose coefficients achieve a $p$-value smaller than some arbitrary threshold (usually 0.05) are declared important determinants of state repression. Using this criteria, the literature has uncovered a number of empirical regularities with respect to state repression. Some concepts have been so consistently related to repression that researchers are now obligated to include measures of them in their models. This list of ``usual suspects'' now includes, at minimum, measures of GDP per capita, population size, civil and international war, and democratic political institutions. Beyond these relationships, the list of concepts that influence repression has been steadily expanded to include INGO presence and behavior \citep{HafnerBurtonTsutsui2005, MurdieDavis2012}, participation in international financial institutions \citep{AbouharbCingranelli2006, AbouharbCingranelli2007}, and domestic legal institutions \citep{Cross1999, KeithTatePoe2009, Mitchell2013}, to name just a few. 

While the current approach has value we argue that, by itself, the standard analysis used in the literature is incomplete at best, and is possibly misleading. Most importantly, scholars have no way of knowing if the patterns they uncover are the result of the peculiarities of a particular data set or whether they are more general. Too, the current approach completely ignores the ability of a model to {\em predict} state repression. This is an important omission since variables that are statistically significant may not meaningfully increase the ability of a model to predict the outcome of interest \citep{Wardetal2010}. While tests for statistical significance have value, evaluating the ability of a model to predict state violence out-of-sample offers at least an additional, and perhaps a better way, of assessing the veracity of potential explanations for its occurrence \citep[See, e.g.][]{BeckKingZeng2000}. That is, significance tests for coefficient(s) are certainly not the only option available, and they may not be the best. 

This study remedies this deficiency in the literature through the use of cross-validation and random forests. Cross-validation is a well-developed and widely-accepted method for assessing the relative predictive performance of statistical models \citep[See, e.g.,][]{Geisser1975, Efron1983, PicardCook1984, HastieTibshiraniFriedman2008}, though its use is relatively rare in political science.\footnote{See \citet{HoffWard2004}, \citet{WardHoff2007}, \citet{WardSiversonCao2007}, and \citet{Wardetal2010} for exceptions.} The cross-validation analysis below assesses the ability of covariates which the literature identifies as important to increase the predictive power of a model of government repression beyond models that include minimal, baseline sets of ``usual suspect'' covariates. 
Random forests, which are ensembles of decision trees, are another useful technique for determining how much predictive power is gained by adding a particular covariate to a statistical model. Decision trees allow us to examine the predictive power that each covariate adds to models that include various combinations of our other covariates, rather than what each covariate adds to the baseline model alone. We find that some, but relatively few, of the concepts identified by the literature as important determinants of state repression are able to substantially improve the fit of statistical models predicting state repression. To foreshadow, out of all the covariates considered, civil conflict is the best predictor of most indicators of state repression. Further, the most studied concept in the literature, democratic political institutions, predicts certain kinds of repression much more accurately than others, which has gone unnoticed in this literature. We argue that this is partly due to conceptual overlap between democracy and particular kinds of state repression. Also, some concepts which have received relatively little attention in the literature, including domestic legal institutions, demographic ``youth bulges,'' and state reliance on natural resource rents, perform quite well. We conclude that some of the concepts providing the largest gains in predictive power indicate a lack of strong theoretical development in the literature, while others that perform well suggest new paths for future theoretical and empirical work. 

\section{A Brief Tour of The Literature}

Cross-national, quantitative research on government repression, which began in earnest in the mid-eighties, was made possible by the publication of annual, national reports on human rights conditions by Freedom House, Amnesty International (AI), and the US State department (USSD). Early work used cross-sections of these data to test hypotheses about the impact of various concepts on repression. The most seminal work in the field is due to \citet{PoeTate1994}, who presented the first analysis using data covering a relatively large time span and a relatively large number of countries. These data were coded from the annual reports of AI and the USSD. \citet{PoeTate1994} found that the coefficients associated with measures of democracy and GDP per capita were negative and statistically significant, and those associated with population size and the occurrence of international and civil wars were significant and positive. A measure of ``leftist'' regimes, too, was found to be positive and significant, though only using the data coded from State Department reports.\footnote{For an analysis of the differences between the two sources see \citet{Poe2001}.} \citet{Poeetal1999} later updated these results using data covering an even larger time period, and additionally found statistically significant relationships between repression and 1) military regimes (positive), 2) former British colonial status (negative), and 3) leftist governments, though this time the relationship was negative for the latter measure. 

At least one of the relationships uncovered by early work, that between repression and democracy \citep{Henderson1991,PoeTate1994}, has been explored in-depth by a number of scholars, who have examined various topics such as how transitions to/from democracy affect repression \citep{Davenport1999}, the functional form of the relationship between democracy and repression \citep{Fein1995,DavenportArmstrong2004}, and which aspects of democracy are most strongly related to repression \citep{BDMetal2005, Davenport2007}. For most research investigating additional potential causes of repression, however, most of the covariates listed above were simply adopted as standard ``control'' variables, particularly population size, GDP per capita, and international and civil war. 

Subsequent work examined the relationship between repression and a variety of potential influences. One body of work focused on the impact of international economic factors such as exposure to trade and foreign investment \citep{Apodaca2001, RichardsGellenySacko2001, HafnerBurton2005jpr},\footnote{\citet{HafnerBurton2005jpr} provides an extensive discussion of this literature, and performs an extreme bounds analysis \citep{LeamerLeonard1983} to address this literature's inconsistent empirical findings. This is a valuable effort, but is motivated by different concerns than those motivating the analysis below. Hafner-Burton's study examines the sensitivity of statistical relationships to the inclusion of different groups of covariates. Her inferences are based on models fitted using all the available data and are drawn on the basis of (a large number of) null hypothesis tests. Thus her analysis does not guard against over-fitting or provide any information about the predictive power of the included covariates.} and participation in IMF and World Bank programs \citep{AbouharbCingranelli2006, AbouharbCingranelli2007}. This work has found, generally, a negative relationship between repression and openness to trade and investment, and a positive relationship between repression and participation in IMF/World Bank structural adjustment programs. \citet{HafnerBurton2005io} focuses on human rights clauses in preferential trade agreements, and finds a negative relationship.\footnote{Though see \citet{SpilkerBohmelt2012}, who use matching techniques prior to their regression analysis and find no relationship between PTAs and repression.} 

Another line of research examines the impact of civil society broadly, and human rights NGO/INGO and Western media activity specifically, on human rights practices \citep{HafnerBurtonTsutsui2005,HafnerBurton2008,MurdieDavis2012}. The impact of NGO/INGO presence on repression has been found to be negative, while results concerning the effects of ``naming and shaming'' are more mixed.\footnote{\citet{HafnerBurton2008} finds positive/null relationships between repression and NGO shaming measures while \citet{MurdieDavis2012} find a negative relationship. The differences are due to different measures, different samples, and the fact that \citet{MurdieDavis2012} interact NGO activity with several other covariates.} 

Yet another group of studies investigates the impact of domestic, and international, legal institutions on state repression \citep{Davenport1996JOP,Cross1999,Hathaway2002,HafnerBurton2005io,Neumayer2005,KeithTatePoe2009,Simmons2009, PowellStaton2009,Hill2010,Lupu2013,Mitchell2013}. Concerning domestic legal institutions, \citet{Davenport1996JOP}, \citet{Cross1999}, and \citet{KeithTatePoe2009} find negative relationships between repression and certain kinds of constitutional provisions, while \citet{Mitchell2013} find that common law legal systems are associated with less repression. \citet{PowellStaton2009} report a negative relationship between {\it de facto} judicial independence and state violence. Most research examining the impact of international law focuses on UN treaties and has found no relationship or even a positive relationship between treaty ratification and repression \citep{Keith1999,Hathaway2002,Hill2010}, while other studies have found positive relationships conditional on certain features of domestic politics and society, including democratic political institutions, a large NGO presence, and the expected tenure of political leaders \citep{Neumayer2005,Simmons2009,ConradRitter2013}. 

Two recent studies have examined other macro-level factors, one evaluating how state reliance on natural resource rents, rather than tax revenue, affects incentives for governments to use repression \citep{DemerittYoung2013},\footnote{The measure of resource rents comes from \citet{Ross2006}.} the other analyzing the relationship between so-called ``youth bulges'' and cross-national levels of state violence \citep{NordaasDavenport2013}.\footnote{They employ a measure from \citet{Urdal2006}.} 

For our purposes we do not need to review all of the theoretical arguments presented in the studies cited above. Our goal is to evaluate whether 1) the relationships discovered by this broad literature are generalizable beyond the particular data sets which produced these relationships, and 2) indicators of the concepts identified as important determinants of state repression improve the predictive power of statistical models of state repression. In the next section we discuss the methods and data used to accomplish this goal.

\section{Evaluating Models of State Repression}
 
As discussed above, the standard criteria for assessing the veracity of a potential explanation for state repression is a null hypothesis test for one or more covariates which measure theoretically relevant concepts. The shortcomings of this criteria for social science research are well documented \citep[See, e.g.][]{Gill1999}, and we do not discuss all of them here. Our concern is that the use of this criteria alone has hindered the development of generalizable and accurate explanations for repression.  Since scholars typically use all of the data available to estimate their models there is a significant danger of over-fitting, i.e. discovering a relationship that is the result of the (perhaps unusual) features of a particular data-set rather than a meaningful relationship between repression and a concept of interest. This is potentially a serious problem since the purpose of cross-national research on state repression is to uncover {\em general} empirical regularities between repression and concepts of interest. Related to this point, strict adherence to null hypothesis tests alone ignores the ability of a model to predict instances of state repression. If a theoretically informed model of state repression has in fact uncovered an important cause of repression, then the model should be able to produce fairly accurate predictions in a set of data which was not used for its estimation \citep[See][]{BeckKingZeng2000,Wardetal2010}. Too, in the context of state violence, creating models with predictive validity will be of significant interest to policymakers. Finally, recent work on civil war has shown that statistical significance and predictive validity can actually be at odds with one another, i.e. covariates with statistically significant coefficients can actually impair a model's predictive performance \citep{Wardetal2010}.  These are important points that have been entirely ignored in the quantitative literature  on government violence. Cross-validation techniques, which we discuss below, can address these omissions.

\subsection{Cross-Validation}

The purpose of cross-validation is to examine the out-of-sample predictive power of a statistical model.\footnote{For a useful introduction to these methods for political science research see \citet{LeeAhlquist2011}.} A typical cross-validation procedure proceeds as follows: the analyst divides the data into $k$ subsets, estimates a model using $k-1$ of the subsets (the ``training'' set), uses these estimates to generate predictions for the remaining subset (the ``test'' set), and calculates some measure of prediction error in the test set. The data are ``rotated'' $k$ times so that each of the $k$ folds is eventually used as the test set, and the prediction error is averaged across the test sets. This is often called $k$-fold cross-validation. Typically the data are divided up a number of times in this fashion to ensure that results are not dependent on dividing the data in a particular way. For the analysis below we perform 10-fold cross-validation.\footnote{In practice the choice of $k$ does not seem to be very consequential, and $k=10$ is fairly standard in the machine learning literature \citep[See, e.g.][]{HastieTibshiraniFriedman2008}.} During the analysis we constrain the folds to have approximate balance on the dependent variable (i.e. the distribution of the dependent variable is approximately the same in all 10 folds). We divide the data into 10 folds, estimate coefficients, and calculate the prediction error across all folds 1,000 times for each model.  Resampling this many times allows us to approximate the uncertainty around the average prediction error for each model, which is useful for comparing performance across models. We describe the statistics used to evaluate predictive performance below. 

\subsection{Random Forests}

We also estimate a set of random forests to assess each covariate's predictive power. Random forests, and their constituent decision trees, are a class of supervised machine learning algorithms that are commonly used for prediction as well as assessing which variables are the most important predictors  \citep[pp. 543-551]{murphy2012machine}.\footnote{Random forests are necessary because decision trees are high variance estimators. Typically bagging, or bootstrapped aggregating, is used to de-correlate the predictions made by each tree in the forest by sampling with replacement both cases and input variables, instead of doing either or neither. We instead use sub-sampling (i.e. sampling without replacement), which has been shown to work better under weaker conditions \citep{politis-sub}.} There are several advantages to this approach. For one, it allows us to consider a particular covariate in combination with all others rather than in combination with only the covariates from the baseline model considered in the cross-validation analysis. Random forests also allow for non-linear functional forms and complex interactions among the covariates.\footnote{Random forests are also equipped to accommodate missing data via surrogate splits \citep{hothorn2006unbiased}. Surrogate splits proceed by ignoring the missing value, calculating the linear statistic for a particular node, finding an optimal split, and then searching for a non-missing variable that results in a similar split.} Decision trees, the constituent parts of a random forest, find an optimal partition of the covariate space through recursive partitioning, sometimes called ``growing'' the tree.\footnote{This typically is accomplished via a ``greedy'' algorithm, i.e. an optimizer that makes the locally optimal choice at each step.} Finding the optimal partition of the input space involves choosing the best variable and the best place to partition said variable. For example, suppose we had two independent variables, $x_1$ and $x_2$, that a researcher believes are related to a dependent variable $y$ in some manner. First, the algorithm would ask which variable was most strongly related to $y$, and then find a threshold $t$ in said variable that maximizes some fit criteria. This procedure is repeated until a stopping criteria is met. Figure \ref{fig:tree} shows this procedure visually. In Figure \ref{fig:tree} $x_1$ and $x_2$ represent covariates, $t_1-t_4$ represent splitting thresholds, and $R_1-R_5$ are the results, or terminal nodes. In the context of classification (i.e., where the dependent variable takes on a set of finite, discrete values), $R_1-R_5$ would represent the distribution of values the dependent variable takes on at that terminal node. In general, the goal is to maximize terminal node ``purity,'' i.e. to have all observations in a terminal node have the same value.\footnote{Terminal node purity is the general goal of decision trees, but this can be measured a number of different ways.} 

\begin{figure}[!htpb]
\Tree[.{$x_1 \leq t_1$} [.{$x_2 \leq t_2$} [.{\small{$R_1$}} ] [.{$x_1 \leq t_3$} [.{\small{$R_4$}} ][.{\small{$R_5$}} ]]] [.{$x_2 \leq t_4$} [.{\small{$R_2$}} ] [.{\small{$R_3$}} ]]]
\caption{An example of recursive partitioning with two variables, $x_1$ and $x_2$, which are related to a variable $y$ in an unknown manner. $R_1-R_5$ represent the distribution of values of the dependent variable at each terminal node in the context of classification.}
\label{fig:tree}
\end{figure}

We utilize the approach of \citet{hothorn2006unbiased}, which first tests the global null hypothesis of no relation between the covariates in the partition $P$, $X_j^P$, where $j$ indexes each covariate. If this global null hypothesis can be rejected at a pre-specified level $\alpha$, then the covariate with the smallest $p$-value is selected, and an optimal split is found. This avoids the established bias towards variables with many possible partitions that occurs in many other random forest implementations, allowing for unbiased variable selection \citep{hothorn2006unbiased, strobl2007bias}.

\subsection{Data and Model Evaluation}

The most commonly employed indicators of state repression in the quantitative literature on that topic are the Cingranelli-Richards (CIRI) physical integrity index \citep{CIRI2010} and the Political Terror Scale (PTS) \citep{GibneyCornettWood2009}. While there are some differences between the two,\footnote{See \citet{WoodGibney2010} and \citet{CingranelliRichards2010}.} both of these are ordinal indicators that measure instances of political imprisonment, torture, kidnapping, and summary executions. The most important difference between these two indicators is that the CIRI physical integrity rights index can be disaggregated into components that measure each of these abusive practices separately. The analysis below employs each of the CIRI components in addition to the PTS and the aggregated CIRI index. This allows us to evaluate whether theoretically informed covariates are better at predicting some repressive practices than others. 

For models using the PTS and the aggregate CIRI index we estimate linear models, which is fairly common practice in the literature. We estimate ordinal logit models for the CIRI component scales, and an additional ordinal model for the PTS. For the linear models, root mean squared error provides a straightforward way of assessing predictive performance.\footnote{Root mean squared error is $\displaystyle \sqrt{\frac{1}{N} \sum\limits_{i=1}^N (\hat{Y_{i}} - Y_{i})^2} $} For ordinal variables such as the CIRI components the choice of a fit statistic is not as obvious. We use Somer's $D$ rank correlation coefficient  \citep{Somers1962} as our discrepancy statistic for the ordinal logit models.
Somer's $D$ is closely related to Goodman and Kruskal's $\gamma$ and Kendall's $\tau$, differing only in the denominator.\footnote{Somer's $D$ is similar to the commonly used $\tau_b$, which is equal to $\frac{P - Q}{(P+Q+X_0)(P+Q+Y_0)}$, where $Y_0$ is the number of ties in $Y$, and $\gamma$, which is equal to $\frac{P - Q}{P + Q}$.} Somer's $D$ makes a distinction between the independent and dependent variable in a bivariate distribution, correcting for ties within the independent variable. With $Y$ being treated as the independent variable it is denoted $D_{xy}$. 
Specifically:
$$D_{xy} = \frac{P - Q}{P + Q + X_0}$$
\noindent where $P$ is the number of concordant pairs, $Q$ is the number discordant pairs, and $X_0$ is the number of ties in $X$. This is simply a measure of association for ordinal variables, so our approach is essentially to calculate the correlation between predicted and observed values. Like all correlation coefficients, the $D$ statistic lies in the interval $[-1, 1]$, with values closer to $1$ indicating more rank agreement and values closer to $1$ indicated less rank agreement, so values closer to -1 indicate more prediction error. In the results section below we discuss how we use these performance measures to judge whether covariates add substantially to a model's predictive ability.

For the random forests, variable importance is assessed using an unscaled permutation test which measures the mean decrease in classification performance after permuting each element of the set of predictors $X_j$ over all trees in the forest. Permuting important variables will result in a systematic decrease in classification accuracy, whereas permuting unimportant variables will result in a random decrease, or no decrease, in classification accuracy.\footnote{The measure of classification accuracy we use here differs from the approach we use to assess variable importance with the ordinal logit models. Here we use a sum of linear statistics, as described in \citet{hothorn2006unbiased}.} The variable importance scores do not measure the importance of the variable conditional on the importance of the other predictors (they measure marginal importance), thus scores can be confounded by correlations between predictors. Although it is possible in principle to conduct a conditional permutation test, such a test is computationally infeasible given the large number of predictors and observations in this study. Figure \ref{fig:cor-cov} shows a correlation matrix of all the predictors used in this study. Although there are some highly correlated pairs, the covariates are not so highly correlated as to make this quasi-experiment uninformative. Notable are the correlations between Polity and its components, as well as those between the media covariates from \citet{RonRamosRodgers2005}. Youth bulges are negatively correlated with Polity and its components, and the INGO measure is positively correlated with Polity. 

\begin{figure}[!htpb]
\includegraphics[width=\textwidth]{./figures/cor-cov.png}
\caption{Correlations Between All Covariates} 
\label{fig:cor-cov}
\end{figure}

Our explanatory variables are drawn from the literature. We use indicators of concepts that are ``usual suspect'' covariates (i.e., standard control variables) as well as indicators for concepts whose relationships with repression are less well-established. Table \ref{tab:vars} lists the measures used below and the sources from which they were obtained. Full descriptions of these data can be found in the appendix. In our cross-validation analysis we assess the increase in predictive validity which results from adding each variable to two different baseline models: one that include only (the natural logs of) GDP per capita and population size, and another that includes both of these variables and an indicator of civil war from the UCDP/PRIO armed conflict data set \citep{ThemnerWallensteen2012}.\footnote{We employ the measure of ``high-intensity'' conflict, i.e. conflict producing $\geq$ 1000 annual battle-related deaths, as this measure performs much better in cross-validation than the ``low-intensity'' measure, which uses a death threshold of 25.}

\begin{table}[htbp!] 
\caption{Measures and Sources} 
\label{tab:vars}
\centering
\begin{tabular}{ll}
Measure & Source \\
\toprule
{\em Demographics} & \\
Population Size & Gleditsch (2002) \\
Youth Population & Urdal (2006) \\ 
\midrule
{\em Macroeconomic Factors} & \\
GDP per capita & Gleditsch (2002) \\
Oil Revenue & Ross (2006) \\ 
\midrule
{\em Violent Conflict} & \\
Civil War & UCDP/PRIO armed conflict \\
Interstate War & UCDP/PRIO armed conflict \\
\midrule
{\em Political Institutions} & \\
Democracy & Polity IV\\
Military Regime & Database of Political Institutions \\
Left/Right Regime & Database of Political Institutions  \\
\midrule
{\em Domestic Legal Institutions} & \\
{\em de facto} Judicial Independence & CIRI \\
Constitutional Provisions & Keith, Tate, and Poe (2009) \\
Common Law System & Mitchell, Ring, and Spellman (2013) \\
\midrule
{\em International Economic Factors} & \\
Trade Openness & World Bank \\
Foreign Direct Investment & World Bank \\
Structural Adjustment (WB and IMF) & Abouharb and Cingranelli (2007) \\
PTA Agreement w/ Human Rights Clause & Spilker and Bohmelt (2012) \\
\midrule
{\em Civil Society/INGOs} & \\
INGO Presence & Hafner-Burton and Tsutsui (2005) \\
INGO Shaming & Ron, Ramos, and Rodgers (2005)  \\
Western Media Shaming & Ron, Ramos, and Rodgers (2005) \\
HRO Shaming & Murdie and Davis (2012) \\
\midrule
{\em International Law} & \\
ICCPR Ratification & UN website \\
CAT Ratification & UN website \\
\bottomrule
\end{tabular}
\end{table}

Several points about the variables used in the analysis are worth mentioning. First, we do not include a lagged dependent variable in any of our models, which flaunts a convention in the literature.\footnote{This seems to have become standard practice as a result of a significant coefficient for a lagged dependent variable in \citet{PoeTate1994}.} We do this because, frankly, we think results for this variable would not be terribly interesting. Our purpose is not to build the best possible predictive model of state repression, but rather to assess the veracity of different theoretical explanations for repression by seeing how well theoretically motivated covariates improve a model's predictive power. While inclusion of a lagged dependent variable would almost undoubtedly serve our interest if prediction alone was our goal, it would not tell us very much about the accuracy of existing explanations for repression. 

Second, for several of the concepts listed in Table \ref{tab:vars} we use multiple measures. These include our measure of democracy, the Polity IV scale \citep{MarshallJaggers2009}, for which we employ both the commonly used ``democracy minus autocracy'' scale, as well as each of the democracy scale components. One study analyzing the Polity data found that the aggregated scale primarily reflects the executive constraints sub-component \citep{GleditschWard1997}, and studies of repression have found that some of the Polity sub-components are more strongly related to repression than others \citep{Keith2002PRQ, BDMetal2005}. We also employ multiple measures of INGO shaming. Three of these come from \citet{RonRamosRodgers2005} and were employed by \citet{HafnerBurton2008}. These are counts of the number of AI press releases and background reports issued about a particular country during a given year. These variables are all lagged by one year. Our other measure of INGO shaming comes from \citet{MurdieDavis2012}. This measure is based on events data and is a count of the annual number of conflictual actions sent by human rights organizations (beyond AI alone) towards a particular government. The constitutional protection data from \citet{KeithTatePoe2009} also includes multiple measures, all found to be statistically significant in regressions using the PTS: provisions for a fair trial, provisions for a public trial, provisions stating that the decisions of high/constitutional courts are final, and provisions which require legislative approval to suspend constitutional liberties. 

Third, as mentioned above, past results for a few of the covariates in Table \ref{tab:vars} are slightly mixed. These are the measures of shaming by INGO/HROs and Western media, and measures of ratification for two core UN human rights conventions: the International Covenant on Civil and Political Rights (ICCPR), and the Convention Against Torture (CAT). \citet{HafnerBurton2008} finds that shaming by Amnesty International (AI) is actually {\it positively} associated with repression, while shaming by Western media bears no relationship to repression, while \citet{MurdieDavis2012} find a negative relationship between NGO shaming and repression conditional on NGO presence and shaming by other actors (such as governments). Results using human rights treaties data have also been mixed, and we employ these indicators because of unexpected, statistically significant findings in the literature, and because we believe the volume of recent work on this topic justifies the inclusion of human rights treaty ratification. 

Finally, many of the variables we use have substantial missingness. Since the assumption that these data are missing at random is implausible, we use model-based imputation of the missing values prior to cross-validation.\footnote{The technical details of the imputation can be found in the appendix.} We perform five imputations of the missing values, cross-validate our models on each imputed data set, and aggregate the prediction error across them. We now turn to the results from our analysis.

\subsection{Results}

For our cross-validation analysis, we adopted the following rule to determine whether the inclusion of a covariate is justified: if the lower bound of the prediction error for the model including that covariate is above the upper bound of the prediction error for the baseline model, then the covariate should be included.\footnote{Since higher values of Somer's $D$ indicate more predictive power, this is the rule for the ordered logit models. For RMSE lower values indicate better predictions, so the rule is reversed, i.e. the upper bound of the model which includes the covariate in question should be below the lower bound for the baseline model.} This is a rather strict rule, but we feel it is justified since we are evaluating the performance of models which include the covariate in question against models that are very stripped-down relative to those common in the literature. Figures \ref{fig:cv-physint}-\ref{fig:cv-cwar-kill} display the median prediction error (shown as dots) as well as the upper and lower bound of the error (shown as lines) for each model we estimate.\footnote{Recall that the data were randomly divided into 10 folds 1000 times for each model.} The models are sorted by the median prediction error from low to high, with a dashed line placed at the upper bound (or lower bound, depending on the discrepancy statistic) of the baseline model. The gray, horizontal bands in each figure highlight the baseline models. 

The first set of figures (\ref{fig:cv-physint}-\ref{fig:cv-kill}) show the consequences of adding different covariates to a model that includes only the natural logs of GDP per capita and population. A passing glance at these figures immediately conveys that civil conflict, for most measures of repression, adds much more predictive power to this baseline model than any other covariate examined here. This is consistent with the observation that governments respond to violent dissent with repression, a phenomenon one scholar \citep{Davenport2007AR} has termed the ``law of coercive response.'' The fact that this relationship is labeled a ``law'' gives some indication of its regularity. We return to this result in the discussion section below. 

Clearly civil war predicts repression better than nearly all of the other covariates, but there are exceptions to this pattern. For the political imprisonment component of the CIRI physical integrity index, civil war is outperformed by the aggregated Polity scale, the CIRI judicial independence measure, and three of the components of the Polity democracy scale, most notably the ``parcomp'' component. This latter result is consistent with previous studies \citep{Keith2002PRQ,BDMetal2005}, though no study we are aware of has noted that democracy predicts political imprisonment more accurately than it does other kinds of government violence. While the performance of Polity and its democracy components is impressive, their ability to predict the imprisonment of political opposition is partly driven by the way Polity defines and operationalizes democracy, which makes any relationship between Polity and political imprisonment tautological. We return to this point below after discussing our other results.

The other measure of government violence for which civil war adds less predictive power than other covariates is the torture component of the CIRI scale. For this indicator the the parcomp scale and the measure of youth population from \citet{Urdal2006} employed by \citet{NordaasDavenport2013},\footnote{This indicator measures the proportion of the adult population (older than 15) that is younger than 25.} both add more predictive power to the baseline model than civil conflict. The concepts measured by the these covariates have received relatively little attention in the literature, and their performance in the analysis warrants closer attention in future theoretical and empirical research. 
 
\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-physint.png}
\caption{}
\label{fig:cv-physint}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-pts-ols.png}
\caption{}
\label{fig:cv-pts-ols}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-pts-lrm.png}
\caption{}
\label{fig:cv-pts-lrm}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-polpris.png}
\caption{}
\label{fig:cv-polpris}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-tort.png}
\caption{}
\label{fig:cv-tort}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-disap.png}
\caption{}
\label{fig:cv-disap}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-kill.png}
\caption{}
\label{fig:cv-kill}
\end{figure}

Figures \ref{fig:cv-cwar-physint}-\ref{fig:cv-cwar-kill} display results from cross-validation analyses in which the baseline model now includes civil war in addition to the natural logs of GDP per capita and population. For the aggregated CIRI scale, the CIRI measure of {\it de facto} judicial independence adds the most predictive power to the baseline model, followed by the measure of youth bulges and the ``parcomp'' scale. Fair trial provisions, oil rents, and common law legal systems, concepts which have only recently received attention in the literature, also perform quite well in this model. For the linear model using the PTS, youth bulges, fair trial provisions, common law legal systems, judicial independence, and ``parcomp'' perform best. Results from the ordinal logit PTS model indicate that youth bulges and judicial independence perform best, followed by the ``parcomp''  and ``xconst'' Polity sub-components. Common law legal systems, fair trial provisions, and oil rents again perform quite well. The impressive performances of  judicial independence, constitutional provisions for fair trials, and common law legal heritage justify a stronger focus on legal institutions in future studies of repression. This is another point to which we return below. 

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-cwar-physint.png}
\caption{}
\label{fig:cv-cwar-physint}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-cwar-pts-ols.png}
\caption{}
\label{fig:cv-cwar-pts-ols}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-cwar-pts-lrm.png}
\caption{}
\label{fig:cv-cwar-pts-lrm}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-cwar-polpris.png}
\caption{}
\label{fig:cv-cwar-polpris}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-cwar-tort.png}
\caption{}
\label{fig:cv-cwar-tort}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-cwar-disap.png}
\caption{}
\label{fig:cv-cwar-disap}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/cv-cwar-kill.png}
\caption{}
\label{fig:cv-cwar-kill}
\end{figure}

Turning to results from the individual CIRI components, the political imprisonment models are largely consistent with those above: the Polity scale and its democracy sub-components perform best, particularly ``parcomp.'' Judicial independence, fair trial provisions, and oil rents also add a substantial amount of predictive power. The results pertaining to torture are also very consistent with the analysis above, with judicial independence and youth bulges adding the most predictive validity to the baseline model. 

The other two CIRI components, which measure disappearance and extrajudicial killing, behave much differently than the other indicators used in this study. Precious few of the covariates included in the analysis add much predictive power to the baseline model. Strict adherence to the decision rule mentioned above leads to the conclusion that only judicial independence, oil rents, youth bulges and INGOs increase the predictive power of the baseline model for disappearance. For extrajudicial killing, only youth bulges, judicial independence, AI press releases, and Western media shaming improve the performance of the baseline model. 

9 of the 31 covariates included in the analysis failed to add predictive power to {\it any} of the baseline models. These are: ratification of the ICCPR, British colonial status, two of the three variables measuring participation in IMF and World Bank structural adjustment programs, constitutional provisions stating that high court decisions are final, constitutional provisions giving the legislature authority over declaration of states of emergency, HRO shaming, foreign direct investment, and international war. That the last two of these fail to add any predictive validity to our baseline models is very surprising. Results are better, but still weak, for ratification of the CAT,\footnote{This measure only improves the fit of the linear PTS model that does not include civil war.} trade openness,\footnote{This variable only adds to the linear PTS model that does not include civil war.} left executive,\footnote{This measure only improves the PTS models that omit civil war and the linear PTS model which includes civil war} participation in World Bank structural adjustment programs,\footnote{Including this covariate only adds to the aggregate CIRI scale model which excludes civil war and the political imprisonment model which excludes civil war} PTAs with human rights clauses,\footnote{This covariate only improves the four aggregate scale (CIRI and PTS) linear models.} and military regimes.\footnote{This variable only improves the fit of the aggregate CIRI scale model which includes civil war.} 

We next turn the the permutation importance measures from the random forests, which are depicted in Figures \ref{fig:physint-imp}-\ref{fig:kill-imp}. These figures show the covariates sorted from most important to least, and also indicate whether the coefficient for each variable achieves statistical significance in a regression model estimated using all of the available data.\footnote{We estimate an OLS model for the aggregated CIRI scale and ordinal logit models for all other dependent variables.} For the most part the results of this analysis echo those from the cross-validation: across most dependent variables, civil war, youth bulges, Polity and some of its sub-components, and judicial independence remain among the most important predictors. As above, Polity and its various components, particularly ``parcomp'' do extremely well in the political imprisonment model. The most notable contrasts with the cross-validation results discussed above are the performances of trade openness and INGO presence. While neither of these performed particularly well in the cross-validation analysis, they score relatively high on our variable importance measure; both add some predictive validity to all of the models save that for the CIRI measure of disappearances. This suggests that these variables may have an interactive or conditional relationship with measures of human rights practices, i.e. their effects are conditioned on other variables. 

As a more general point, it is worth noting that statistical significance does not perfectly correlate with variable importance. There is certainly a positive correlation between the two, but clearly statistical significance is neither necessary nor sufficient for predictive validity. For example, trade openness is not significant in the political imprisonment or torture models, but is judged to add more predictive power to these models than all but a few other covariates. As another example, though both international war and PTAs with human rights clauses are statistically significant in {\em every} model, including these measures adds very little predictive power to any of the models. The first of these is recognized in the literature as one of the more well-established causes of repression, but this analysis suggests that this relationship is not very general. The larger point about predictive power versus significance is in line with the findings at least one previous study \citep{Wardetal2010}, but bears mentioning as it is not widely appreciated.\footnote{Coefficient plots for each variable from regression models using all of the available data can be found in the appendix.} 

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/physint-imp-sig.png}
\caption{}
\label{fig:physint-imp}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/pts-imp-sig.png}
\caption{}
\label{fig:pts-imp}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/polpris-imp-sig.png}
\caption{}
\label{fig:polpris-imp}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/disap-imp-sig.png}
\caption{}
\label{fig:disap-imp}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/tort-imp-sig.png}
\caption{}
\label{fig:tort-imp}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/kill-imp-sig.png}
\caption{}
\label{fig:kill-imp}
\end{figure}

\section{Discussion/Conclusion}

What do these results tell us about the state of the empirical literature on human rights violations? At least two of the relationships that are well-established in the literature seem to generalize beyond particular sets of data: those between repression and civil war, and repression and democracy. The first of these results strongly suggests, in line with previous studies, that when government/dissident military violence produces a large number of deaths, governments often target non-combatants with violence.\footnote{Neither the CIRI scales nor the PTS include battle-related deaths.} Given the usual Weberian conception of the state as an organization that possesses a monopoly on the organized use of force within a delimited geographic area, it is unsurprising that when this monopoly is threatened governments respond violently. Obviously the relationship between dissident and government violence is strongly reciprocal, yet theoretical work on the dynamics of political violence is thin \citep[But see, e.g.][]{Moore2000,Pierskalla2010,RitterJCR}. Given that reciprocal violence producing civil war (as operationalized here) is such a strong predictor of repression, more theoretical work is sorely needed. 

The relationship between democracy and repression is also very general. To measure democracy we employed the Polity data, which contains the most commonly used measures in the literature. Results were particularly strong with respect to the ``parcomp'' democratic component, and this component along with the other components and the aggregated scale added a tremendous amount of predictive power to the political imprisonment models. This result is partly the result of conceptual overlap between democracy and repression. The Polity codebook \citep[][p.\ 26]{MarshallJaggers2009} makes it clear that the ``parcomp'' sub-component in particular partly {\it measures repression}. The lowest category, called ``repressed,'' is defined as follows:
\begin{quote}
No significant oppositional activity is permitted outside the ranks of the regime and ruling party. Totalitarian party systems, authoritarian military dictatorships, and despotic monarchies are typically coded here. {\it However, the mere existence of these structures is not sufficient for a ``Repressed'' coding. The regime's institutional structure must also be matched by its demonstrated ability to repress oppositional competition} (emphasis added).
\end{quote}
\noindent
Examples of activities that may justify coding a state in the bottom three categories of this scale are:
\begin{quote}
Systematic harassment of political opposition ({\em leaders killed, jailed,} or sent into exile; candidates regularly ruled off ballots; opposition media banned, etc.) (emphasis added). 
\end{quote}
\noindent
Thus the fact that Polity predicts very well the imprisonment of political opponents and the aggregated repression scales, which both include information about political imprisonment, should not be very surprising. For the PTS this problem is especially bad since the scale cannot be disaggregated to exclude political imprisonment. Unfortunately this is also a problem for the CIRI scale to the extent that governments are repressing political opposition through the use of torture, kidnapping, and summary execution. This is because targeting political opponents with these tactics also reduces a governments level of democracy {\it by definition}, given the way that concept is usually defined in this literature. This is a point that has gone unnoticed in empirical studies of repression,\footnote{Reference removed.} and it means that one of the strongest results in the literature is actually the result of estimating what are essentially tautological statistical models. For future work, correcting this problem entails removing government violence that explicitly targets political opponents from the study's dependent variable, if one wishes to employ political competition as a covariate. Or, one could model political repression but remove political competition from the list of covariates included in the model. 

Future theoretical work on repression should also take this point seriously, which entails developing arguments about why governments would have incentives to repress political opponents that do not use political competition as an explanatory concept. One possibility is suggested by the results for oil rents, which \citet{DemerittYoung2013} theorize as related to repression because of the (lack of) incentives to protect human rights that results from increasing non-reliance on citizen-generated revenue. They note that this is consistent with arguments from the literature on democratization \citep[E.g.][]{Huntington1991,BDMSmith2009}. This is a nice theoretical insight, since explanations for why governments would stop violently suppressing political competition are, in some sense, explanations for the emergence of democracy. Future work would benefit from incorporating more insights from the democratization literature about how economic conditions, for example asset mobility and inequality, affect leader's incentives to repress political opposition \citep[See, e.g.][]{Boix2003,AcemogluRobinson2005,ClarkGolderGolder2013}. 

Other promising results here are those for certain features of domestic legal systems, including judicial independence, constitutional guarantees for fair trials, and common law heritage. Judicial independence in particular performed well in both analyses, outperforming even civil war in predicting torture. There is a nascent literature on domestic courts and human rights violations, and most of this literature examines the interaction between domestic courts and international law \citep{Hathaway2007,PowellStaton2009,Simmons2009,Conrad2012,ConradRitter2013,Lupu2013}. The results here strongly suggest that the relationship between domestic courts and repression is very general and does not depend on a government's ratification status for various international human rights treaties, so studying the impact of domestic courts themselves on repression would be useful. This concept deserves more attention in future theoretical and empirical work, and should probably be operationalized and included as a matter of course in statistical models of repression.\footnote{See \citet{RiosStaton2012} for a review of existing measures of judicial independence, and \citet{LinzerStaton2011} for a promising approach to measuring that concept.} 

Regarding constitutional rights protections, the results for fair trial provisions suggest that formal legal protection of basic rights may indeed be more than a ``parchment barrier,'' \citep[See][]{KeithTatePoe2009} and justifies more attention to the law itself, including criminal trial procedures, in future studies.\footnote{See \citet{Cross1999}, who laments a lack of attention to the law in research on human rights violations.} The performance of the common law heritage measure used by \citet{Mitchell2013} also suggests that legal institutions deserve more attention, though the policy implications of this finding are not obvious since legal system type is not malleable. Overall, legal institutions have received far less attention in the literature than democratic political institutions, and the performance of these three legal institutions measures merits further research. Further, since legal institutions are not {\it tautologically} related to repression they represent a more fruitful path for future research than additional studies of democracy and repression, at least for studies using the data we employ. 

One rather surprising result was the excellent performance of the youth bulges measure used by \citet{NordasDavenport2013}. The theoretical reason for the relationship between a large per capita youth population and repression is preemptive action, on the part of the government, to prevent large-scale rebellion. The strength of this result suggests that demographic factors beyond mere population size should be more closely examined in the future. 

A final point is that prediction {\it per se} was not our explicit goal. If it was, there are several ways we could improve the accuracy of the regression models used in the cross-validation analysis. We mention above the improved accuracy that would likely result from the inclusion of a lagged dependent variable. More complicated strategies for modeling temporal dynamics may also be helpful,\footnote{See, e.g., \citep{Brandtetal2011}} though data on repression are usually collected at a high level of temporal aggregation. Mixture models, such as ``zero-inflated'' models, offer another promising approach \citep[See, e.g.][]{Bagozzietal2013,Bagozzi2013}. Also, the estimators we use treat these observations as independent, which is standard practice in the literature, but using a model that more realistically accounts for the structure of the data would undoubtedly result in better predictions.\footnote{E.g., mixed effects models would markedly improve our predictions. See the modeling strategy presented in \citet{Wardetal2012}.} Most importantly, we wish to stress that the predictive ability of theoretically motivated covariates should be used more often to evaluate the accuracy of theoretical explanations for government violence.

\newpage
\begin{singlespace}
\bibliographystyle{apsr}
\bibliography{hill_jones_hr}
\end{singlespace}

\appendix
\section{Appendix}

\subsection{Data Descriptions}

Data on population and trade come from \citet{gleditsch2002expanded}. These are data from the Penn World Tables \citep{summers1991penn} with missing values imputed using information from the CIA World Factbook and procedures described fully in \citet{gleditsch2002expanded}. 

The measure of youth bulges used above comes from \citet{Urdal2006}, who uses demographic data from the UN to construct a measure of the proportion of the adult population (older than 15) that is younger than 25.

The indicator of oil rents is due to \citet{Ross2006}, and measures the total value of oil and natural gas production, accounting for extraction costs. This figure is divided by mid-year population. 

Data on civil and interstate war come from the UCDP/PRIO armed conflict data set \citep{ThemnerWallensteen2012}. The civil war variable is equal to one for all years in which a country experienced conflict between the government and rebel groups resulting in at least 1000 battle-related deaths. The interstate war variable is equal to one for years in which a country's government was involved in a militarized conflict with another government resulting in at least 1000 battle deaths.

All of our measures of democracy come from the Polity IV regime characteristics data \citep{MarshallJaggers2009}. The democracy component of Polity is comprised of four sub-components which measure competitiveness of executive recruitment, openness of executive recruitment, executive constraints, and the competitiveness of participation. We use each of these individual components in the analysis. The most commonly used indicator of democracy results from subtracting the aggregated autocracy scale (which measures the four characteristics above in addition to the regulation of participation) from the aggregated democracy scale. We also use this measure in the analysis.  

Information on military regimes and leftist regimes comes from the Database of Political Institutions \citep{beck2001new}. The military regime variable is coded one if the chief executive is a military officer or an officer who has not formally retired from the military before assuming office. The leftist regime variable is coded one for chief executives identified as communist, socialist, social democratic, or left-wing based on their economic policies. 

Data on constitutional provisions come from \citet{KeithTatePoe2009}. These are all binary and are created by 
coding the text of national constitutions. The variables we use indicate the presence of provisions for a fair trial, provisions for a public trial, provisions stating that the decisions of high/constitutional courts are final, and provisions which require legislative approval to suspend constitutional liberties. 

The measure of common law legal systems comes from \citet{powell2007international}. This is a binary variable coded one if a country's legal system has primarily features of a common law system. Other possible categories are civil law, Islamic law, and mixed legal system.

Measures of trade openness and foreign direct investment both come from the World Bank's World Development Indicators \citep{WorldBank2012}. These measure trade as a percentage of GDP and FDI net inflows as a percentage of GDP. 

Indicators for participation in IMF and World Bank structural adjustment programs come from \citet{AbouharbCingranelli2007}. We use three binary indicators, one which is coded one if a government is currently participating in an IMF structural adjustment program, another which is equal to one if a government is participating in a World Bank structural adjustment program, and another which is coded one if a government is participating in structural adjustment programs with both the World Bank and the IMF.

Data on preferential trade agreements (PTAs) with human rights clauses comes from \citet{SpilkerBohmelt2012}. This variable is coded one for all years a government is a member of at least one PTA with a ``hard'' human rights clause. A hard clause is defined as one that explicitly mentions human rights principles and also declares that the benefits of the agreement are conditional on observing those principles. 

Our measure of INGO presence comes from \citet{HafnerBurtonTsutsui2005}, and is a count of the number of INGOs of which a government's citizens are members. Two of our three INGO shaming measures come from \citet{RonRamosRodgers2005}. These are counts of the annual number of press releases and background reports issued by Amnesty International about a particular country. From \citet{MurdieDavis2012} we use an events data-based measure which is a count of the annual number of conflictual actions human rights organizations send to a particular government. As a fourth shaming measure we use another variable from \citet{RonRamosRodgers2005} which measures the annual, average number of stories about a particular country published in Western media outlets (Newsweek and The Economist) which mention human rights practices. 

Finally, our measures of UN treaty ratification status are taken from the UN website.\footnote{\url{http://treaties.un.org/Pages/Treaties.aspx?id=4&subid=A&lang=en}} We use two indicators, one coded one for every year a country has ratified the Convention Against Torture, and another indicating ratification status for the International Covenant on Civil and Political Rights. 

\subsection{Imputation}

To impute missing values in our data we use a combination of classification trees and the random indicator method \citep{buuren2011mice,jolani2012}. The random indicator is designed to deal with data that is not missing at random, that is, when the values of the variable with missingness are related to the probability of missingness. Imputing data that is not missing at random (NMAR) as if it is missing at random (MAR) may skew the distribution of the variable, biasing results. Formally, for NMAR data, $\text{Pr}(Y|X, R=1) \neq \text{Pr}(Y|X, R=0)$ if we let $Y$ be a random variable with some missingness, $R$ be the indicator function which equals 1 when the value of $Y$ is observed and 0 otherwise, and $X$ be a fully-observed covariate. The random indicator method works by first estimating a model of the probability of response $\hat{R}$ and comparing the conditional distribution of $Y$ given $R$ and $\hat{R}$. An offset $\delta_R = E(Y|R=1,\hat{R}=1) - E(Y|R=1,\hat{R}=0)$ is estimated, which, under the assumption that the variance of the missing values and the observed values of $Y$ are equal, is equivalent to $\delta_{NR} = E(Y|R=0,\hat{R}=1) - E(Y|R=0,\hat{R}=0)$ \citep{jolani2012}. Although the missingness mechanism is unknown, we use the random indicator method for all continuous covariates and classification trees for all binary, ordinal, or categorical covariates (excluding Polity and its components, which are imputed using the random indicator method). The distribution of the imputed and observed values for all variables with missingness are shown in Figure \ref{fig:mi}.

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/mi.png}
\caption{The distribution of observed (shown in blue) and imputed (shown in red) values for all covariates with missingness. Categorical variables are imputed using classification trees and continuous variables are imputed using the random indicator method.}
\label{fig:mi}
\end{figure}

\subsection{Coefficient Estimates}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/all-physint.png}
\caption{}
\label{fig:all-physint}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/all-pts-ols.png}
\caption{}
\label{fig:all-pts-ols}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/all-pts-lrm.png}
\caption{}
\label{fig:all-pts-lrm}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/all-polpris.png}
\caption{}
\label{fig:all-polpris}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/all-tort.png}
\caption{}
\label{fig:all-tort}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/all-disap.png}
\caption{}
\label{fig:all-disap}
\end{figure}

\begin{figure}[!htpb]
\centering
\includegraphics[width=\textwidth]{./figures/all-kill.png}
\caption{}
\label{fig:all-kill}
\end{figure}

\end{document}